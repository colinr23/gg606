[
["index.html", "Scientific Data Wrangling Chapter 1 Introduction 1.1 Textbooks 1.2 Cheatsheets 1.3 Additional Readings 1.4 Schedule 1.5 Evaluation", " Scientific Data Wrangling Colin Robertson 2022-02-17 Chapter 1 Introduction Class Time: Thursdays, 2:30 - 5:20, Peters Building P331 Moving from data acquired by a sensor or in the field to a model or visualization that can provide insights to a question often requires an extensive amount of work. It is estimated that ‘data wrangling’ - cleaning, loading, processing, integrating their data comprises at least half of a data scientist’s time, and that may be even higher in the context of environmental data science. The official course outline is available here 1.1 Textbooks Wickham H, Grolemund G. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media. Chicago, available online at http://r4ds.had.co.nz/ Timbers, T-A., Campbell, T., and Lee, M. 2021. Introducation to Data Science https://ubc-dsci.github.io/introduction-to-datascience/ 1.2 Cheatsheets Use these R-Studio Cheatsheets 1.3 Additional Readings Broman KW, Woo KH. 2018. Data Organization in Spreadsheets. The American Statistician 72(1): 2-10. https://doi.org/10.1080/00031305.2017.1375989 Bryan J, et al. 2018. Happy Git and GitHub for the useR. http://happygitwithr.com/ Hampton SE, Anderson SS, Bagby SC, Gries C, Han X, Hart EM, Jones MB, Lenhardt WC, MacDonald A, Michener WK, Mudge J, Pourmokhtarian A, Schildhauer MP, Woo KH, Zimmerman N. 2015. The Tao of open science for ecology. Ecosphere 6(7):120. http://dx.doi.org/10.1890/ES14-00402.1 Hart EM, Barmby P, LeBauer D, Michonneau F, Mount S, Mulrooney P, et al. 2016. Ten Simple Rules for Digital Data Storage. PLoS Comput Biol12(10): e1005097. https://doi.org/10.1371/journal.pcbi.1005097 Sixteen peer-reviewed journal articles in the PeerJ Collection, Practical Data Science for Stats: https://peerj.com/collections/50-practicaldatascistats/ Wilke CO. 2019. Fundamental of Data Visualization: A Primer on Making Informative and Compelling Figures. O’Reilly Media. Chicago, https://serialmentor.com/dataviz/ 1.4 Schedule Wrangling Week Topic Tools Jan 6 Data/Science workflows R, R-Studio Jan 13 i/o R (base, tidyverse) Jan 20 Data objects R (tidyverse) Jan 27 Databases R (tidyverse, dbply), SQLite Feb 03 Spatial data R (rgdal, sp, sf, raster, terra) Feb 10 Spatial data R (spatstat, gstat) Feb 17 Work Period/Catch up Feb 24 Reading Week Mar 03 Temporal data R (ts, zoo, lubridate) Data Science in Practice Week Topic Tools Mar 10 Reproducible Research Git, Github Mar 17 Data Sharing and Collaboration R Markdown, Docker Mar 24 Project Work Period Mar 31 R in Production Docker, R-Shiny Apr 07 Project Presentations n/a 1.5 Evaluation Evaluation in the course will be comprised of a mix of hands-on components designed to build skills in environmental data science. There will be two assignments and one project required for the course. Students will be required to give a technical demonstration of their work and a project write-up. 1.5.1 Grading Assessment Component Weighting Due Date Assignments (2X15%) 30% Feb 10, Mar 03 Analytics Studio Demo 40% Mar 31, Apr 07 Participation 15% N/A Course notebook 15% Apr 07 Total: 100% "],
["intro.html", "Chapter 2 Wrangling 2.1 Data Science Workflows 2.2 i/o 2.3 Data objects 2.4 Databases 2.5 Spatial data 2.6 Temporal data", " Chapter 2 Wrangling 2.1 Data Science Workflows 2.1.1 Reading This week will provide an introduction to data science using r. You will be introduced to data science through the lens of exploratory data analysis, beginning with the Explore section of the textbook, read and work through the following chapters: W&amp;G - Introduction W&amp;G - Data visualization W&amp;G - Data Transformation W&amp;G - Workflow: basics W&amp;G - Workflow: scripts W&amp;G - Workflow: projects 2.1.2 Excercise Review Data Visualization: 1, 2, 3, 4, 5, 6 Workflow: basics: 1 2.2 i/o 2.2.1 Reading This week will cover the surprisingly important topic of data i/o - that is, data importing and outputting data. In the Wrangle section of the textbook, read and work through the following chapters: JHDSc - Data import W&amp;G - Tidy data As well as the paper describing the tidy approach to data, published in the Journal of Statistical Software. R documentation - Review of Data Import/Export Data sources and formats vary widely in environmental data analytics. Data acquisition is the steps taken to access and load data for your own analysis. In a classic analysis workflow architecture, data are downloaded to a local working computer and interact with software installed there to complete your analysis. Raw data almost always has to be processed in different ways to make it useful. This can in include Quality Assurance/Quality Control (QA/QC) steps such as checking and removing duplicate records, cleaning out special characters from text, to things like date formatting and computing derived variables. Having a consistent way to generate data transformations is a cornerstone of reproducible research and modern scientific data workflows. This is one of the key reasons scripting has become so important to environmental data analytics. The tidy approach to data science aims to provide a cohesive and consistent approach to data organization in r. 2.3 Data objects 2.3.1 Reading We will cover some more basic elements of the R programming language - both at the base and more modern levels. At some point having an understanding of how R works at a deeper level becomes necessary to get the most out of it and develop effective analysis and visualization approaches. Wickham - Vectors TCL - Wrangling 2.4 Databases 2.4.1 Resources There are no dedicated readings this week, but below are some of the resources discussed during class this week. R-studio docs Examples of lazy execution 2.5 Spatial data Spatial data wrangling encompasses a set of techniques usually found in standard GIS courses. Tasks such as spatial query, spatial overlay, combining vector and raster data, are all often necessary steps in preparing spatial data for analysis. Due to the mature collection of packages for working with spatial data n r, all of these operations can be performed in r, generally through a tidy workflow. 2.5.1 Reading 501 Lecture slides for review Pebezma 2018 Pebezma - geom Pebezma - sf Gimond Appendix- Walk-thru of common spatial operations 2.6 Temporal data "],
["practice.html", "Chapter 3 Practice", " Chapter 3 Practice "],
["assignments.html", "Chapter 4 Assignments 4.1 Assignment 1 - Importing, parsing, and querying data in the wild 4.2 Assignment 2 - Real world data wrangling", " Chapter 4 Assignments 4.1 Assignment 1 - Importing, parsing, and querying data in the wild Your objective in this assignment is to read in, clean, and process a dataset. The due date of this assignment has shifted to Feb 10. 4.1.1 Dataset The National Earthquake Information Center (NEIC) determines the location and size of all significant earthquakes that occur worldwide and disseminates this information immediately to national and international agencies, scientists, critical facilities, and the general public. The NEIC compiles and provides to scientists and to the public an extensive seismic database that serves as a foundation for scientific research through the operation of modern digital national and global seismograph networks and cooperative international agreements. The NEIC is the national data center and archive for earthquake information. This dataset includes a record of the date, time, location, depth, magnitude, and source of every earthquake with a reported magnitude 5.5 or higher since 1965. You have to structure your assignment as a r mardown file. Watch this video (~45 mins) to learn how to start and navigate markdown files in R-Studio. Disclaimer: I am not endorsing buying these courses - this is just a straightforward introduction to get up to up and running with R-markdown. You can use the following as a template [download to your working directory, and open in R-studio to edit/knit] to get you started for your assignment. Your assignment should answer the following questions and be as reproducible as you can make it (i.e., I should be able to reproduce your answers).This means that you must read data in from a URL so that I can replicate your work, do not include any external data files in your submission, only submit one .Rmd file. You can use external data to supplement your anlayses if you want to. For each answer provide a short write up explaining the approach you took to the question. There are not necessarily correct answers, and I expect your answers to vary from classmates, however you should be able to provide a clear illustration via your code of how you arrived at the conclusion you did. 4.1.2 Questions Read the data in and clean it for analysis, used the readr package functions for reading and parsing data. [5 marks] Did more earthquakes happen on weekends or weekdays? [5 marks] Has there been any change in the frequency of earthquakes? [5 marks] What had more earthquakes in the 1980s, South America or North America? [5 marks] Has there been any geographic shifts in the distribution of earthquakes? [10 marks] 4.1.3 Submission Submit via email to Colin at the start of class on Feb 10 4.2 Assignment 2 - Real world data wrangling The Canadian Census from 2021 will soon be released and made available to the public. You will analyze Canadian census data for this assignment. However, the real goal of this assignment is to get you familiar with the process of learning a new r package. More than anything - the r landscape of packages is quickly changing and being able to learn about, understand, and use new packages is a vital skill for scientific data wrangling. Often, new published papers will have relatedr packages and may or may not have clear documentaiton or vignetttes (which are best for getting up and running). Evaluating an r package requires quickly ascertaining whether a package can do what you need it to, how to format data for it, what outputs are generated, and what parameters need to be set/configured. There is very little standardization across r packages (outside of the tidyverse) so this step of evaluation can take some time. Your goal for this assignment is to get up and running with the cancensus package. You can learn more about the cancensus package here. To submit for this assignment: a reproducible R markdown file that develops an analysis of census data for a geographical location in Canada of interest to you. You are free to incorporate external data from other sources if you wish, but the focus should be on data that are in the census. The geography of interest must meet the following criteria: has a name that starts with same letter as your first name or last name is comprised of at least 30 geographic units is somewhere that you have not personally visited The analysis may focus on traditional census themes like population change or dive deep into more specific demographic or regional questions. Your analysis should present a coherent data story, and should mix visualizaitons and written interpretations of your analysis. You must include all r code for reprorducing your report, however do not have to show all of the code in the output in the final report (i.e. you can have echo=FALSE in some of your code chunks if you want them hidden from the output - learn how to use chunk options in R-studio). Focus on quality over quantity, only include analysis which contributes to your overally narrative, do not include every type of graph or model you explored. "],
["term-project-analytics-studio-demo.html", "Chapter 5 Term Project - Analytics Studio Demo 5.1 Overview 5.2 Submission", " Chapter 5 Term Project - Analytics Studio Demo 5.1 Overview The goal of this project is to demonstrate a technical topic to an audience in an interesting way. Being able to communicate technical details in accessible ways is a critical skill for working with collaborators on scientific projects. People need to know what you did, what decisions were made and why, how they affected the outcome, and potential issues or shortcomings in the approach taken. While peer-review is one part of the scientific knowledge production process - increasingly it is not sufficient to just describe your methods in a paper, but these must be presented as supplementary code or a notebook which documents exact data processing steps. Your task for the term project is to provide a complete analytic walk-thru of an existing analysis from a paper in an area of interest (i.e., replicated by you) or through a demonstration of a specialized statistical or analysis method through the use of r packages. If you are demoing a method this must be a completely new demonstration and ideally will compare and contrast multiple packages, not simply a rehashing of an existing tutorial or vignette. Please consult with me to confirm your chosen topic. There are two fundamental parts to this projet, demonstration, and critique. 5.1.1 Demonstration In this part of the project your goal is to articulate as clearly as possible to a scientific but non-specialized audience the full scope of your analysis. This should comprise about half of your written report and about 70% of your presentation/overview in class. 5.1.2 Critique In this part of the project you should critically analyze the analysis and/or methods implemented in the package. Focus here on issues of data quality, uncertainty, key parameters, workflow, etc. Your aim here is to provide a critical overview of the methods and analysis presented so as to provide guidance and advice to scientific collaborators. 5.2 Submission The term project here is comprised of a written report and an in-class demonstration (i.e., delivered via zoom for remote participants). The report will be worth 65 points according to the following breakdown: Technical depth - /40 Critique - /25 Accuracy - /20 Writing style - /15 The presentation will be worth 35 points and graded according to the following breakdown: Aesthetic appeal - /25 Clarity and communication style - /25 Technical completeness - /50 The report should be no longer than 4000 words. The presentation should be between 13-15 minutes. The presentation file will not be submitted for grading. "]
]
